"""
Vertex AI Agent for Guardian - Enhanced with Google GenAI
Advanced emergency analysis using Google Generative AI and Vertex AI
"""
import logging
import json
import requests
import os
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False

class VertexAIAgent:
    """Agent Vertex AI pour l'analyse d'urgence avanc√©e avec Gemini via API REST"""
    
    def __init__(self, api_keys_config: Dict[str, Any] = None):
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        
        # Configuration API - Prioriser Gemini sur Vertex AI
        self.api_keys_config = api_keys_config or {}
        google_config = self.api_keys_config.get('google_cloud', {})
        
        # Configuration Gemini (prioritaire)
        gemini_config = google_config.get('gemini', {})
        vertex_config = google_config.get('vertex_ai', {})
        
        # Utiliser Gemini si disponible, sinon Vertex AI
        if gemini_config.get('enabled', False) and gemini_config.get('api_key'):
            self.api_key = gemini_config.get('api_key')
            self.model_name = gemini_config.get('model', 'gemini-1.5-flash-latest')
            self.base_url = gemini_config.get('base_url', 'https://generativelanguage.googleapis.com/v1beta')
            self.api_type = 'gemini'
            self.logger.info("Configuration: API Gemini (Generative Language)")
        else:
            # Fallback vers Vertex AI
            self.api_key = vertex_config.get('api_key')
            self.model_name = "gemini-1.5-flash-002"
            self.region = vertex_config.get('region', 'europe-west1')
            self.api_type = 'vertex'
            self.logger.info("Configuration: Vertex AI (fallback)")
            
        self.project_id = google_config.get('project_id')
        self.enabled = gemini_config.get('enabled', vertex_config.get('enabled', True))
        
        self.is_available = False
        
        # Initialiser l'API si configuration compl√®te
        if self.api_key and self.enabled:
            self._initialize_api()
        else:
            self.logger.warning("Configuration API incompl√®te - fonctionnement en mode simulation")
    
    def _initialize_api(self):
        """Initialise la connexion √† l'API Gemini/Vertex AI"""
        try:
            # Initialiser le client Google GenAI si disponible
            if self.api_type == 'gemini' and GENAI_AVAILABLE:
                self._initialize_genai_client()
            
            # Test de connectivit√© simple
            test_prompt = "Test. R√©pondez juste 'OK'."
            
            response = self._make_api_request(test_prompt, max_tokens=5)
            
            if response and 'candidates' in response:
                # V√©rifier que ce n'est pas une simulation
                response_text = response['candidates'][0]['content']['parts'][0]['text']
                if response_text and 'simulation' not in response_text.lower():
                    self.is_available = True
                    self.logger.info(f"‚úÖ API {self.api_type.upper()} connect√©e avec succ√®s")
                    return
                    
            # Si on arrive ici, c'est une simulation ou erreur
            self.is_available = False
            self.logger.info(f"‚ö†Ô∏è Mode simulation activ√© pour {self.api_type.upper()}")
                
        except Exception as e:
            self.logger.error(f"Erreur initialisation API {self.api_type}: {e}")
            self.is_available = False
    
    def _initialize_genai_client(self):
        """Initialise le client Google GenAI moderne"""
        try:
            if self.api_key and GENAI_AVAILABLE:
                # Configurer la variable d'environnement
                os.environ['GEMINI_API_KEY'] = self.api_key
                
                # Cr√©er le client
                self.genai_client = genai.Client()
                self.use_genai_client = True
                self.logger.info("‚úÖ Client Google GenAI initialis√©")
            else:
                self.use_genai_client = False
                self.logger.info("‚ö†Ô∏è Client Google GenAI non disponible - utilisation REST")
        except Exception as e:
            self.logger.error(f"Erreur initialisation client GenAI: {e}")
            self.use_genai_client = False
    
    def _make_api_request(self, prompt: str, max_tokens: int = 1000) -> Optional[Dict]:
        """Effectue une requ√™te √† l'API Gemini"""
        if not self.api_key or self.api_key == "YOUR_VERTEX_AI_API_KEY":
            self.logger.info("API Key non configur√©e - mode simulation")
            return self._simulate_response(prompt)
        
        # Utiliser le client Google GenAI moderne si disponible
        if hasattr(self, 'use_genai_client') and self.use_genai_client and hasattr(self, 'genai_client'):
            return self._make_genai_request(prompt, max_tokens)
        
        # Construire l'URL selon le type d'API (m√©thode REST classique)
        try:
            if self.api_type == 'gemini':
                api_url = f"{self.base_url}/models/{self.model_name}:generateContent?key={self.api_key}"
            else:
                # Vertex AI (fallback)
                api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key={self.api_key}"
            
            headers = {
                'Content-Type': 'application/json'
            }
            
            payload = {
                "contents": [{
                    "parts": [{"text": prompt}]
                }],
                "generationConfig": {
                    "temperature": 0.1,
                    "maxOutputTokens": max_tokens,
                    "topP": 0.8,
                    "topK": 10
                },
                "safetySettings": [
                    {
                        "category": "HARM_CATEGORY_HARASSMENT",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                    },
                    {
                        "category": "HARM_CATEGORY_HATE_SPEECH",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                    },
                    {
                        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                    },
                    {
                        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                    }
                ]
            }
            
            self.logger.debug(f"Requ√™te API {self.api_type}: {api_url[:50]}...")
            response = requests.post(api_url, headers=headers, json=payload, timeout=15)
            
            self.logger.debug(f"R√©ponse API: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                self.logger.info("API Gemini: R√©ponse re√ßue avec succ√®s")
                return result
            elif response.status_code == 400:
                error_detail = response.text
                self.logger.warning(f"API Gemini erreur 400 (Bad Request): {error_detail[:200]}...")
                self.logger.info("Passage en mode simulation")
                return self._simulate_response(prompt)
            elif response.status_code == 403:
                self.logger.warning("API Gemini: Cl√© invalide ou API non activ√©e - mode simulation")
                return self._simulate_response(prompt)
            else:
                self.logger.warning(f"API Gemini erreur {response.status_code}: {response.text[:100]}...")
                return self._simulate_response(prompt)
                
        except requests.exceptions.RequestException as e:
            self.logger.warning(f"Erreur r√©seau API Gemini: {e} - mode simulation")
            return self._simulate_response(prompt)
        except Exception as e:
            self.logger.warning(f"Erreur API Gemini: {e} - mode simulation")
            return self._simulate_response(prompt)
    
    def _make_genai_request(self, prompt: str, max_tokens: int = 1000) -> Optional[Dict]:
        """Effectue une requ√™te avec le nouveau client Google GenAI"""
        try:
            self.logger.info("üöÄ Utilisation du client Google GenAI moderne")
            
            # G√©n√©rer le contenu avec le nouveau client
            # Utiliser gemini-2.5-flash qui fonctionne
            response = self.genai_client.models.generate_content(
                model="gemini-2.5-flash", 
                contents=prompt
            )
            
            # Convertir la r√©ponse au format attendu
            if response and hasattr(response, 'text'):
                formatted_response = {
                    "candidates": [
                        {
                            "content": {
                                "parts": [
                                    {
                                        "text": response.text
                                    }
                                ]
                            },
                            "finishReason": "STOP"
                        }
                    ]
                }
                self.logger.info("‚úÖ R√©ponse Google GenAI re√ßue avec succ√®s")
                return formatted_response
            else:
                self.logger.warning("‚ö†Ô∏è R√©ponse Google GenAI vide")
                return self._simulate_response(prompt)
                
        except Exception as e:
            self.logger.warning(f"‚ùå Erreur Google GenAI: {e} - basculement vers simulation")
            
            # Diagnostics sp√©cifiques pour aider l'utilisateur
            error_str = str(e)
            if "403" in error_str or "PERMISSION_DENIED" in error_str:
                self.logger.info("üí° Cl√© API invalide ou service bloqu√©")
            elif "404" in error_str or "not found" in error_str.lower():
                self.logger.info("üí° Mod√®le non trouv√© - essayez avec une cl√© API valide")
            elif "quota" in error_str.lower():
                self.logger.info("üí° Quota API d√©pass√©")
                
            return self._simulate_response(prompt)
    
    def _simulate_response(self, prompt: str) -> Dict:
        """Generate simulated response based on contextual analysis"""
        self.logger.info("Vertex AI simulation mode - advanced analysis")
        
        # Analyse approfondie du prompt pour une r√©ponse tr√®s r√©aliste
        prompt_lower = prompt.lower()
        
        # D√©tection de mots-cl√©s et contextes
        urgency_indicators = {
            'critique': ['inconscient', 'sang', 'arr√™t cardiaque', 'ne respire plus', 'accident grave'],
            '√©lev√©e': ['chute', 'douleur intense', 'bless√©', 'cass√©', 'fracture', 'malaise'],
            'mod√©r√©e': ['perdu', 'peur', 'inquiet', 'mal', 'probl√®me'],
            'faible': ['conseil', 'information', 'aide', 'question']
        }
        
        medical_keywords = ['douleur', 'mal', 'bless√©', 'sang', 'chute', 'malaise', '√©tourdissement']
        security_keywords = ['danger', 'agression', 'menace', 'peur', 'suspect']
        location_keywords = ['perdu', '√©gar√©', 'ne sais pas o√π', 'trouve plus']
        
        # Analyze urgency level
        urgency_level = 3  # default
        urgency_category = "Mod√©r√©e"
        
        for level, keywords in urgency_indicators.items():
            if any(word in prompt_lower for word in keywords):
                if level == 'critique':
                    urgency_level = 9
                    urgency_category = "Critique"
                elif level == '√©lev√©e':
                    urgency_level = 7
                    urgency_category = "√âlev√©e"
                elif level == 'mod√©r√©e':
                    urgency_level = 5
                    urgency_category = "Mod√©r√©e"
                else:
                    urgency_level = 2
                    urgency_category = "Faible"
                break
        
        # Generate detailed contextual response
        if any(word in prompt_lower for word in ['chute', 'tomb√©', 'chu', 'gliss√©']):
            body_parts = ['bras', 'jambe', 'dos', 't√™te', 'cheville', 'poignet', 'genou']
            injured_part = next((part for part in body_parts if part in prompt_lower), "corps")
            
            simulated_analysis = {
                "emergency_type": f"Traumatisme suite √† chute - {injured_part}",
                "urgency_level": min(urgency_level + 2, 10),
                "urgency_category": "√âlev√©e",
                "immediate_actions": [
                    f"√âvaluer la douleur du {injured_part}",
                    "Immobiliser la zone si fracture suspect√©e",
                    "Appliquer de la glace si possible"
                ],
                "specific_advice": f"Chute avec impact sur le {injured_part}. Si douleur intense ou d√©formation visible, consultez rapidement. Surveillez les signes de commotion si impact √† la t√™te.",
                "emergency_services": "SAMU (15) si douleur s√©v√®re",
                "reassurance_message": "Restez calme et √©valuez vos sympt√¥mes.",
                "recommended_actions": [
                    "Tester la mobilit√© progressivement",
                    "Surveiller l'√©volution de la douleur",
                    "Consulter si sympt√¥mes persistent"
                ]
            }
        elif any(word in prompt_lower for word in security_keywords):
            threat_level = "√©lev√©e" if any(word in prompt_lower for word in ['agression', 'menace', 'danger imm√©diat']) else "mod√©r√©e"
            
            simulated_analysis = {
                "emergency_type": f"Situation de s√©curit√© - menace {threat_level}",
                "urgency_level": 9 if threat_level == "√©lev√©e" else 7,
                "urgency_category": "Critique" if threat_level == "√©lev√©e" else "√âlev√©e",
                "immediate_actions": [
                    "√âloignez-vous de la source de danger",
                    "Dirigez-vous vers un lieu public s√ªr",
                    "Contactez imm√©diatement les forces de l'ordre"
                ],
                "specific_advice": f"Situation de s√©curit√© n√©cessitant une r√©action imm√©diate. Priorit√© absolue : votre s√©curit√© personnelle. Ne prenez aucun risque inutile.",
                "emergency_services": "Police (17) ou Urgences (112)",
                "reassurance_message": "Les forces de s√©curit√© sont form√©es pour g√©rer ces situations. Votre s√©curit√© est la priorit√©.",
                "safety_tips": [
                    "Restez dans des zones √©clair√©es et fr√©quent√©es",
                    "Gardez votre t√©l√©phone accessible",
                    "Signalez votre position aux autorit√©s"
                ]
            }
        elif any(word in prompt_lower for word in medical_keywords):
            # Analyse des sympt√¥mes m√©dicaux
            symptoms = []
            if 'douleur' in prompt_lower:
                symptoms.append('douleur')
            if 'malaise' in prompt_lower:
                symptoms.append('malaise')
            if '√©tourdissement' in prompt_lower:
                symptoms.append('√©tourdissement')
                
            intensity_words = ['intense', 's√©v√®re', 'insupportable', 'tr√®s fort']
            is_severe = any(word in prompt_lower for word in intensity_words)
            
            simulated_analysis = {
                "emergency_type": f"Urgence m√©dicale - {', '.join(symptoms) if symptoms else 'sympt√¥mes divers'}",
                "urgency_level": min(urgency_level + (3 if is_severe else 1), 10),
                "urgency_category": "Critique" if is_severe else "√âlev√©e",
                "immediate_actions": [
                    "Trouvez une position confortable (assis ou allong√©)",
                    "Contr√¥lez votre respiration (inspirations lentes et profondes)",
                    "√âvaluez l'intensit√© des sympt√¥mes sur 10"
                ],
                "specific_advice": f"Sympt√¥mes m√©dicaux {'s√©v√®res' if is_severe else 'mod√©r√©s'} n√©cessitant {'une intervention imm√©diate' if is_severe else 'une √©valuation m√©dicale'}. {'Appelez le 15 maintenant' if is_severe else 'Surveillez l √©volution et consultez si aggravation'}.",
                "emergency_services": "SAMU (15)" if is_severe else "M√©decin traitant ou SOS M√©decins",
                "reassurance_message": "Les √©quipes m√©dicales sont sp√©cialis√©es dans la gestion de ces sympt√¥mes. Une prise en charge adapt√©e est disponible.",
                "monitoring_advice": [
                    "Notez l'heure d'apparition des sympt√¥mes",
                    "Surveillez l'√©volution (am√©lioration/aggravation)",
                    "Pr√©parez vos ant√©c√©dents m√©dicaux"
                ]
            }
        else:
            simulated_analysis = {
                "emergency_type": "Urgence g√©n√©rale",
                "urgency_level": 6,
                "urgency_category": "Mod√©r√©e",
                "immediate_actions": [
                    "√âvaluer la situation",
                    "Rester calme",
                    "Contacter les personnes appropri√©es"
                ],
                "specific_advice": "Situation n√©cessitant une attention particuli√®re mais pas de panique.",
                "emergency_services": "Num√©ro d'urgence europ√©en (112)",
                "reassurance_message": "La situation est sous contr√¥le et l'aide arrive.",
                "follow_up_needed": True
            }
        
        # Ajouter des champs par d√©faut
        simulated_analysis.setdefault("risk_factors", ["√âvaluation en cours"])
        simulated_analysis.setdefault("what3words", "")
        
        return {
            'candidates': [{
                'content': {
                    'parts': [{'text': json.dumps(simulated_analysis)}]
                }
            }]
        }
    
    def analyze_emergency_situation(self, context: str, location: Tuple[float, float] = None, 
                                  user_input: str = "", time_of_day: str = "jour") -> Dict[str, Any]:
        """Analyse une situation d'urgence avec Vertex AI Gemini"""
        
        # Construction du prompt contextuel
        location_str = f"GPS {location[0]:.6f}, {location[1]:.6f}" if location else "Non disponible"
        
        # Construction d'un prompt structur√© pour Gemini
        prompt = f"""Tu es un assistant d'urgence sp√©cialis√©. Analyse la situation suivante et r√©ponds uniquement avec un JSON valide contenant ces champs exacts:

Situation: {context}
Moment: {time_of_day}
Localisation: {location_str}
Description: {user_input if user_input else 'Aucune information suppl√©mentaire'}

R√©ponds UNIQUEMENT avec ce JSON (sans autre texte):
{{
  "emergency_type": "type d'urgence d√©tect√©",
  "urgency_level": nombre de 1 √† 10,
  "urgency_category": "Faible/Mod√©r√©e/√âlev√©e/Critique",
  "specific_advice": "conseil personnalis√© en fran√ßais",
  "immediate_actions": ["action1", "action2", "action3"],
  "emergency_services": "service d'urgence recommand√©",
  "reassurance_message": "message rassurant"
}}"""
        
        try:
            response = self._make_api_request(prompt, max_tokens=800)
            
            if response and 'candidates' in response:
                response_text = response['candidates'][0]['content']['parts'][0]['text']
                
                try:
                    analysis = json.loads(response_text.strip())
                    analysis = self._validate_analysis_response(analysis)
                    
                    self.logger.info("Analyse Vertex AI g√©n√©r√©e avec succ√®s")
                    return analysis
                    
                except json.JSONDecodeError as e:
                    self.logger.error(f"Erreur parsing JSON: {e}")
                    return self._fallback_analysis(context)
            
        except Exception as e:
            self.logger.error(f"Erreur analyse Vertex AI: {e}")
        
        return self._fallback_analysis(context)
    
    def _validate_analysis_response(self, analysis: Dict) -> Dict:
        """Valide et nettoie la r√©ponse de l'analyse"""
        
        defaults = {
            "emergency_type": "Urgence",
            "urgency_level": 5,
            "urgency_category": "Mod√©r√©e", 
            "immediate_actions": ["√âvaluer la situation", "Rester calme"],
            "specific_advice": "Situation n√©cessitant attention",
            "emergency_services": "112",
            "reassurance_message": "L'aide est en route",
            "follow_up_needed": True,
            "risk_factors": ["√âvaluation n√©cessaire"],
            "what3words": ""
        }
        
        # Appliquer les valeurs par d√©faut
        for key, default_value in defaults.items():
            if key not in analysis:
                analysis[key] = default_value
        
        # Validation du niveau d'urgence
        try:
            urgency = int(analysis.get('urgency_level', 5))
            analysis['urgency_level'] = max(1, min(10, urgency))
        except (ValueError, TypeError):
            analysis['urgency_level'] = 5
        
        # Validation des actions (max 3)
        actions = analysis.get('immediate_actions', [])
        if isinstance(actions, list) and len(actions) > 3:
            analysis['immediate_actions'] = actions[:3]
        
        return analysis
    
    def _fallback_analysis(self, context: str) -> Dict[str, Any]:
        """Analyse de fallback si Vertex AI √©choue"""
        self.logger.warning("Utilisation analyse de fallback")
        
        context_lower = context.lower()
        
        if any(word in context_lower for word in ['chute', 'tomb√©', 'fall']):
            urgency = 8
            emergency_type = "Chute d√©tect√©e"
            services = "SAMU (15)"
        elif any(word in context_lower for word in ['agression', 'attaque', 'danger']):
            urgency = 9
            emergency_type = "Situation dangereuse"
            services = "Police (17)"
        elif any(word in context_lower for word in ['malaise', 'douleur', 'm√©dical']):
            urgency = 7
            emergency_type = "Urgence m√©dicale"
            services = "SAMU (15)"
        else:
            urgency = 6
            emergency_type = "Urgence g√©n√©rale"
            services = "Num√©ro d'urgence (112)"
        
        return {
            "emergency_type": emergency_type,
            "urgency_level": urgency,
            "urgency_category": "√âlev√©e" if urgency >= 8 else "Mod√©r√©e",
            "immediate_actions": [
                "√âvaluer la situation",
                "Assurer la s√©curit√©", 
                "Demander de l'aide si n√©cessaire"
            ],
            "specific_advice": f"Situation identifi√©e comme: {emergency_type}. Surveillance recommand√©e.",
            "emergency_services": services,
            "reassurance_message": "Nous sommes l√† pour vous aider.",
            "follow_up_needed": True,
            "risk_factors": ["√âvaluation en cours"],
            "what3words": ""
        }
    
    def analyze_fall_emergency(self, fall_info: Dict, user_response: str = None, 
                              context: str = "") -> Dict[str, Any]:
        """Analyse sp√©cialis√©e pour les chutes"""
        
        impact_force = fall_info.get('impact_force', 'mod√©r√©')
        duration = fall_info.get('duration_seconds', 0)
        movement_after = fall_info.get('movement_detected_after', False)
        
        prompt_parts = [
            "Analyse de chute d'urgence:",
            f"Force d'impact: {impact_force}",
            f"Dur√©e: {duration} secondes",
            f"Mouvement apr√®s: {movement_after}",
            f"R√©ponse utilisateur: {user_response or 'Aucune'}",
            f"Contexte: {context}"
        ]
        
        prompt = " | ".join(prompt_parts)
        
        try:
            response = self._make_api_request(prompt, max_tokens=600)
            
            if response and 'candidates' in response:
                response_text = response['candidates'][0]['content']['parts'][0]['text']
                
                try:
                    analysis = json.loads(response_text.strip())
                    analysis = self._validate_fall_analysis(analysis)
                    return analysis
                    
                except json.JSONDecodeError:
                    return self._fallback_fall_analysis(fall_info, user_response)
        
        except Exception as e:
            self.logger.error(f"Erreur analyse chute: {e}")
        
        return self._fallback_fall_analysis(fall_info, user_response)
    
    def _validate_fall_analysis(self, analysis: Dict) -> Dict:
        """Valide l'analyse de chute"""
        
        defaults = {
            "emergency_type": "Chute d√©tect√©e",
            "urgency_level": 7,
            "urgency_category": "√âlev√©e",
            "immediate_actions": ["Ne pas bouger", "V√©rifier conscience", "Appeler secours"],
            "specific_advice": "Chute d√©tect√©e - √©valuation m√©dicale recommand√©e",
            "emergency_services": "SAMU (15)",
            "reassurance_message": "Les secours m√©dicaux peuvent intervenir rapidement",
            "medical_priority": "√âlev√©e",
            "recommended_position": "Ne pas d√©placer",
            "follow_up_needed": True
        }
        
        for key, default_value in defaults.items():
            if key not in analysis:
                analysis[key] = default_value
        
        return analysis
    
    def _fallback_fall_analysis(self, fall_info: Dict, user_response: str) -> Dict:
        """Analyse de fallback pour les chutes"""
        
        impact = fall_info.get('impact_force', 'mod√©r√©')
        movement = fall_info.get('movement_detected_after', False)
        
        if impact == 'fort' or not movement:
            urgency = 9
            priority = "Critique"
        elif user_response and 'va bien' in user_response.lower():
            urgency = 6
            priority = "Moyenne"
        else:
            urgency = 8
            priority = "√âlev√©e"
        
        return {
            "emergency_type": "Chute d√©tect√©e",
            "urgency_level": urgency,
            "urgency_category": "Critique" if urgency >= 9 else "√âlev√©e",
            "immediate_actions": [
                "Ne pas d√©placer la personne",
                "V√©rifier la conscience",
                "Appeler les secours m√©dicaux"
            ],
            "specific_advice": f"Chute avec impact {impact}. √âvaluation m√©dicale n√©cessaire.",
            "emergency_services": "SAMU (15)",
            "reassurance_message": "Une chute a √©t√© d√©tect√©e. Les secours sont alert√©s.",
            "medical_priority": priority,
            "recommended_position": "Position de s√©curit√©, ne pas bouger",
            "follow_up_needed": True
        }
    
    def get_personalized_emergency_message(self, analysis: Dict) -> str:
        """Generate personalized emergency message"""
        
        emergency_type = analysis.get('emergency_type', 'Urgence')
        urgency_level = analysis.get('urgency_level', 5)
        advice = analysis.get('specific_advice', '')
        
        if urgency_level >= 8:
            intensity = "URGENCE CRITIQUE"
        elif urgency_level >= 6:
            intensity = "URGENCE √âLEV√âE"
        else:
            intensity = "SITUATION √Ä SURVEILLER"
        
        message = f"{intensity}\n"
        message += f"Type: {emergency_type}\n"
        message += f"Niveau: {urgency_level}/10\n\n"
        message += f"Conseil: {advice}"
        
        return message
    
    def test_connection(self) -> bool:
        """Test la connexion √† l'API Vertex AI"""
        try:
            response = self._make_api_request("Test", max_tokens=5)
            return response is not None and 'candidates' in response
        except:
            return False
    
    def test_vertex_ai_connection(self) -> Dict[str, Any]:
        """Test la connexion Vertex AI avec retour d√©taill√© (compatibilit√©)"""
        try:
            # Test de base
            connection_ok = self.test_connection()
            
            if connection_ok and self.is_available:
                return {
                    "success": True,
                    "available": True,
                    "details": f"Mod√®le: {self.model_name}, R√©gion: {self.region}",
                    "message": "Vertex AI REST API connect√©e avec succ√®s"
                }
            else:
                return {
                    "success": False,
                    "available": False,
                    "details": f"Mode simulation - Mod√®le: {self.model_name}",
                    "message": "Vertex AI en mode simulation (cl√© API manquante ou OAuth2 non impl√©ment√©)"
                }
        
        except Exception as e:
            return {
                "success": False,
                "available": False,
                "details": "Erreur de connexion",
                "message": f"Erreur de connexion: {e}"
            }