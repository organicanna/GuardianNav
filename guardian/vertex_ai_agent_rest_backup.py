"""
Vertex AI Agent for GuardianNav - API REST Version
Advanced emergency analysis using Google Cloud Vertex AI via REST API
Plus simple et plus flexible que les SDKs
"""
import logging
import json
import requests
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
import time

class VertexAIAgent:
    """Agent Vertex AI pour l'analyse d'urgence avanc√©e avec Gemini via API REST"""
    
    def __init__(self, api_keys_config: Dict[str, Any] = None):
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        
        # Configuration API
        self.api_keys_config = api_keys_config or {}
        vertex_config = self.api_keys_config.get('google_cloud', {}).get('vertex_ai', {})
        
        self.project_id = self.api_keys_config.get('google_cloud', {}).get('project_id')
        self.region = vertex_config.get('region', 'europe-west1')
        self.api_key = vertex_config.get('api_key')
        self.enabled = vertex_config.get('enabled', True)
        
        # Configuration du mod√®le
        self.model_name = "gemini-1.5-flash-002"  # Mod√®le le plus r√©cent
        self.is_available = False
        
        # URL de base pour l'API Vertex AI
        if self.project_id and self.api_key:
            self.base_url = f"https://{self.region}-aiplatform.googleapis.com/v1/projects/{self.project_id}/locations/{self.region}/publishers/google/models/{self.model_name}"
            self._initialize_api()
        else:
            self.logger.warning("Configuration Vertex AI incompl√®te - fonctionnement en mode simulation")
    
    def _initialize_api(self):
        """Initialise la connexion √† l'API Vertex AI"""
        try:
            # Test de connectivit√© avec une requ√™te simple
            test_prompt = "Test de connectivit√©. R√©pondez simplement 'OK'."
            
            response = self._make_api_request(test_prompt, max_tokens=10)
            
            if response and 'candidates' in response:
                self.is_available = True
                self.logger.info("‚úÖ Vertex AI API initialis√©e avec succ√®s")
            else:
                self.logger.warning("‚ö†Ô∏è API Vertex AI - r√©ponse inattendue")
                
        except Exception as e:
            self.logger.error(f"‚ùå Erreur initialisation Vertex AI API: {e}")
            self.logger.info("üîÑ Fonctionnement en mode simulation")
    
    def _make_api_request(self, prompt: str, max_tokens: int = 1000, temperature: float = 0.1) -> Optional[Dict]:
        """Effectue une requ√™te √† l'API Vertex AI"""
        if not self.api_key or not self.project_id:
            return self._simulate_response(prompt)
        
        url = f"{self.base_url}:generateContent"
        
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            'contents': [{
                'role': 'user',
                'parts': [{'text': prompt}]
            }],
            'generation_config': {
                'temperature': temperature,
                'maxOutputTokens': max_tokens,
                'topP': 0.95,
                'topK': 40
            },
            'safety_settings': [
                {
                    'category': 'HARM_CATEGORY_DANGEROUS_CONTENT',
                    'threshold': 'BLOCK_NONE'  # Permet le contenu d'urgence
                },
                {
                    'category': 'HARM_CATEGORY_HARASSMENT', 
                    'threshold': 'BLOCK_ONLY_HIGH'
                }
            ]
        }
        
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=10)
            
            if response.status_code == 200:
                return response.json()
            else:
                self.logger.error(f"Erreur API Vertex AI: {response.status_code} - {response.text}")
                return self._simulate_response(prompt)
                
        except Exception as e:
            self.logger.error(f"Exception API Vertex AI: {e}")
            return self._simulate_response(prompt)
    
    def _simulate_response(self, prompt: str) -> Dict:
        """G√©n√®re une r√©ponse simul√©e pour les tests"""
        self.logger.info("üé≠ Mode simulation Vertex AI")
        
        # Analyse du prompt pour g√©n√©rer une r√©ponse coh√©rente
        if "chute" in prompt.lower() or "fall" in prompt.lower():
            simulated_text = json.dumps({
                "emergency_type": "Chute d√©tect√©e",
                "urgency_level": 8,
                "urgency_category": "√âlev√©e",
                "immediate_actions": [
                    "V√©rifier si la personne est consciente",
                    "Ne pas d√©placer en cas de blessure",
                    "Appeler les secours si n√©cessaire"
                ],
                "specific_advice": "Une chute peut causer des blessures internes. Surveillance m√©dicale recommand√©e.",
                "emergency_services": "SAMU (15)",
                "reassurance_message": "Les secours sont pr√©venus et peuvent intervenir rapidement.",
                "follow_up_needed": True
            })
        else:
            simulated_text = json.dumps({
                "emergency_type": "Urgence g√©n√©rale",
                "urgency_level": 6,
                "urgency_category": "Mod√©r√©e",
                "immediate_actions": [
                    "√âvaluer la situation",
                    "Rester calme",
                    "Contacter les personnes appropri√©es"
                ],
                "specific_advice": "Situation n√©cessitant une attention particuli√®re mais pas de panique.",
                "emergency_services": "Num√©ro d'urgence europ√©en (112)",
                "reassurance_message": "La situation est sous contr√¥le et l'aide arrive.",
                "follow_up_needed": True
            })
        
        return {
            'candidates': [{
                'content': {
                    'parts': [{'text': simulated_text}]
                }
            }]
        }
    
    def analyze_emergency_situation(self, context: str, location: Tuple[float, float] = None, 
                                  user_input: str = "", time_of_day: str = "jour") -> Dict[str, Any]:
        """
        Analyse une situation d'urgence avec Vertex AI Gemini
        
        Args:
            context: Description de la situation
            location: Coordonn√©es GPS (lat, lon)
            user_input: R√©ponse/description de l'utilisateur
            time_of_day: Moment de la journ√©e
        
        Returns:
            Dict contenant l'analyse compl√®te
        """
        
        # Construction du prompt contextuel
        prompt = f"""Tu es un expert en gestion d'urgences. Analyse cette situation et fournis une r√©ponse JSON structur√©e.

SITUATION D'URGENCE:
- Contexte: {context}
- Moment: {time_of_day}
- Localisation: {f"GPS {location[0]:.6f}, {location[1]:.6f}" if location else "Non disponible"}
- Description utilisateur: {user_input if user_input else "Aucune"}

ANALYSE DEMAND√âE:
Fournis une r√©ponse JSON UNIQUEMENT avec cette structure exacte:
{{
    "emergency_type": "Type pr√©cis d'urgence",
    "urgency_level": 1-10,
    "urgency_category": "Faible|Mod√©r√©e|√âlev√©e|Critique",
    "immediate_actions": ["Action 1", "Action 2", "Action 3"],
    "specific_advice": "Conseil sp√©cialis√© pour cette situation",
    "emergency_services": "Service recommand√© (ex: SAMU 15, Police 17, Pompiers 18, 112)",
    "reassurance_message": "Message rassurant personnalis√©",
    "follow_up_needed": true/false,
    "risk_factors": ["Facteur 1", "Facteur 2"],
    "what3words": "code.trois.mots"
}}

R√©ponds SEULEMENT avec le JSON, aucun autre texte."""

        try:
            response = self._make_api_request(prompt, max_tokens=800, temperature=0.2)
            
            if response and 'candidates' in response:
                response_text = response['candidates'][0]['content']['parts'][0]['text']
                
                # Parser la r√©ponse JSON
                try:
                    analysis = json.loads(response_text.strip())
                    
                    # Validation et nettoyage
                    analysis = self._validate_analysis_response(analysis)
                    
                    self.logger.info("‚úÖ Analyse Vertex AI g√©n√©r√©e avec succ√®s")
                    return analysis
                    
                except json.JSONDecodeError as e:
                    self.logger.error(f"Erreur parsing JSON Vertex AI: {e}")
                    return self._fallback_analysis(context)
            
        except Exception as e:
            self.logger.error(f"Erreur analyse Vertex AI: {e}")
        
        return self._fallback_analysis(context)
    
    def _validate_analysis_response(self, analysis: Dict) -> Dict:
        """Valide et nettoie la r√©ponse de l'analyse"""
        
        # Valeurs par d√©faut
        defaults = {
            "emergency_type": "Urgence",
            "urgency_level": 5,
            "urgency_category": "Mod√©r√©e", 
            "immediate_actions": ["√âvaluer la situation", "Rester calme"],
            "specific_advice": "Situation n√©cessitant attention",
            "emergency_services": "112",
            "reassurance_message": "L'aide est en route",
            "follow_up_needed": True,
            "risk_factors": ["√âvaluation n√©cessaire"],
            "what3words": ""
        }
        
        # Appliquer les valeurs par d√©faut pour les cl√©s manquantes
        for key, default_value in defaults.items():
            if key not in analysis:
                analysis[key] = default_value
        
        # Validation du niveau d'urgence
        try:
            urgency = int(analysis.get('urgency_level', 5))
            analysis['urgency_level'] = max(1, min(10, urgency))
        except (ValueError, TypeError):
            analysis['urgency_level'] = 5
        
        # Validation des actions (max 3)
        actions = analysis.get('immediate_actions', [])
        if isinstance(actions, list) and len(actions) > 3:
            analysis['immediate_actions'] = actions[:3]
        
        return analysis
    
    def _fallback_analysis(self, context: str) -> Dict[str, Any]:
        """Analyse de fallback si Vertex AI √©choue"""
        self.logger.warning("üîÑ Utilisation analyse de fallback")
        
        # Analyse basique par mots-cl√©s
        context_lower = context.lower()
        
        if any(word in context_lower for word in ['chute', 'tomb√©', 'fall']):
            urgency = 8
            emergency_type = "Chute d√©tect√©e"
            services = "SAMU (15)"
        elif any(word in context_lower for word in ['agression', 'attaque', 'danger']):
            urgency = 9
            emergency_type = "Situation dangereuse"
            services = "Police (17)"
        elif any(word in context_lower for word in ['malaise', 'douleur', 'm√©dical']):
            urgency = 7
            emergency_type = "Urgence m√©dicale"
            services = "SAMU (15)"
        else:
            urgency = 6
            emergency_type = "Urgence g√©n√©rale"
            services = "Num√©ro d'urgence (112)"
        
        return {
            "emergency_type": emergency_type,
            "urgency_level": urgency,
            "urgency_category": "√âlev√©e" if urgency >= 8 else "Mod√©r√©e",
            "immediate_actions": [
                "√âvaluer la situation",
                "Assurer la s√©curit√©", 
                "Demander de l'aide si n√©cessaire"
            ],
            "specific_advice": f"Situation identifi√©e comme: {emergency_type}. Surveillance recommand√©e.",
            "emergency_services": services,
            "reassurance_message": "Nous sommes l√† pour vous aider.",
            "follow_up_needed": True,
            "risk_factors": ["√âvaluation en cours"],
            "what3words": ""
        }
    
    def analyze_fall_emergency(self, fall_info: Dict, user_response: str = None, 
                              context: str = "") -> Dict[str, Any]:
        """
        Analyse sp√©cialis√©e pour les chutes
        """
        
        # Informations sur la chute
        impact_force = fall_info.get('impact_force', 'mod√©r√©')
        duration = fall_info.get('duration_seconds', 0)
        movement_after = fall_info.get('movement_detected_after', False)
        
        prompt = f\"\"\"Analyse cette situation de chute d'urgence. Fournis une r√©ponse JSON UNIQUEMENT.

CHUTE D√âTECT√âE:
- Force d'impact: {impact_force}
- Dur√©e de la chute: {duration} secondes
- Mouvement apr√®s chute: {movement_after}
- R√©ponse utilisateur: "{user_response if user_response else 'Aucune r√©ponse'}"
- Contexte: {context}

Fournis une r√©ponse JSON avec cette structure:
{{
    "emergency_type": "Type sp√©cifique de chute",
    "urgency_level": 1-10,
    "urgency_category": "Faible|Mod√©r√©e|√âlev√©e|Critique", 
    "immediate_actions": ["Action 1", "Action 2", "Action 3"],
    "specific_advice": "Conseil m√©dical sp√©cialis√© pour cette chute",
    "emergency_services": "Service m√©dical recommand√©",
    "reassurance_message": "Message adapt√© √† la situation de chute",
    "medical_priority": "Faible|Moyenne|√âlev√©e|Critique",
    "recommended_position": "Position recommand√©e pour la personne",
    "follow_up_needed": true/false
}}

R√©ponds SEULEMENT avec le JSON.\"\"\"

        try:
            response = self._make_api_request(prompt, max_tokens=600, temperature=0.15)
            
            if response and 'candidates' in response:
                response_text = response['candidates'][0]['content']['parts'][0]['text']
                
                try:
                    analysis = json.loads(response_text.strip())
                    analysis = self._validate_fall_analysis(analysis)
                    return analysis
                    
                except json.JSONDecodeError:
                    return self._fallback_fall_analysis(fall_info, user_response)
        
        except Exception as e:
            self.logger.error(f"Erreur analyse chute Vertex AI: {e}")
        
        return self._fallback_fall_analysis(fall_info, user_response)
    
    def _validate_fall_analysis(self, analysis: Dict) -> Dict:
        """Valide l'analyse de chute"""
        
        defaults = {
            "emergency_type": "Chute d√©tect√©e",
            "urgency_level": 7,
            "urgency_category": "√âlev√©e",
            "immediate_actions": ["Ne pas bouger", "V√©rifier conscience", "Appeler secours"],
            "specific_advice": "Chute d√©tect√©e - √©valuation m√©dicale recommand√©e",
            "emergency_services": "SAMU (15)",
            "reassurance_message": "Les secours m√©dicaux peuvent intervenir rapidement",
            "medical_priority": "√âlev√©e",
            "recommended_position": "Ne pas d√©placer",
            "follow_up_needed": True
        }
        
        for key, default_value in defaults.items():
            if key not in analysis:
                analysis[key] = default_value
        
        return analysis
    
    def _fallback_fall_analysis(self, fall_info: Dict, user_response: str) -> Dict:
        """Analyse de fallback pour les chutes"""
        
        # √âvaluation bas√©e sur les donn√©es de chute
        impact = fall_info.get('impact_force', 'mod√©r√©')
        movement = fall_info.get('movement_detected_after', False)
        
        if impact == 'fort' or not movement:
            urgency = 9
            priority = "Critique"
        elif user_response and 'va bien' in user_response.lower():
            urgency = 6
            priority = "Moyenne"
        else:
            urgency = 8
            priority = "√âlev√©e"
        
        return {
            "emergency_type": "Chute d√©tect√©e",
            "urgency_level": urgency,
            "urgency_category": "Critique" if urgency >= 9 else "√âlev√©e",
            "immediate_actions": [
                "Ne pas d√©placer la personne",
                "V√©rifier la conscience",
                "Appeler les secours m√©dicaux"
            ],
            "specific_advice": f"Chute avec impact {impact}. √âvaluation m√©dicale n√©cessaire.",
            "emergency_services": "SAMU (15)",
            "reassurance_message": "Une chute a √©t√© d√©tect√©e. Les secours sont alert√©s.",
            "medical_priority": priority,
            "recommended_position": "Position de s√©curit√©, ne pas bouger",
            "follow_up_needed": True
        }
    
    def get_personalized_emergency_message(self, analysis: Dict) -> str:
        """G√©n√®re un message d'urgence personnalis√©"""
        
        emergency_type = analysis.get('emergency_type', 'Urgence')
        urgency_level = analysis.get('urgency_level', 5)
        advice = analysis.get('specific_advice', '')
        
        if urgency_level >= 8:
            intensity = "üö® URGENCE CRITIQUE"
        elif urgency_level >= 6:
            intensity = "‚ö†Ô∏è URGENCE √âLEV√âE"
        else:
            intensity = "üìã SITUATION √Ä SURVEILLER"
        
        message = f"{intensity}\n"
        message += f"Type: {emergency_type}\n"
        message += f"Niveau: {urgency_level}/10\n\n"
        message += f"üí° Conseil: {advice}"
        
        return message
    
    def test_connection(self) -> bool:
        """Test la connexion √† l'API Vertex AI"""
        try:
            response = self._make_api_request("Test", max_tokens=5)
            return response is not None and 'candidates' in response
        except:
            return False