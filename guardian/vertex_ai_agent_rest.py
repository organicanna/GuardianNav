"""
Vertex AI Agent for GuardianNav - API REST Version
Advanced emergency analysis using Google Cloud Vertex AI via REST API
"""
import logging
import json
import requests
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime

class VertexAIAgent:
    """Agent Vertex AI pour l'analyse d'urgence avanc√©e avec Gemini via API REST"""
    
    def __init__(self, api_keys_config: Dict[str, Any] = None):
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        
        # Configuration API
        self.api_keys_config = api_keys_config or {}
        vertex_config = self.api_keys_config.get('google_cloud', {}).get('vertex_ai', {})
        
        self.project_id = self.api_keys_config.get('google_cloud', {}).get('project_id')
        self.region = vertex_config.get('region', 'europe-west1')
        self.api_key = vertex_config.get('api_key')
        self.enabled = vertex_config.get('enabled', True)
        
        # Configuration du mod√®le
        self.model_name = "gemini-1.5-flash-002"
        self.is_available = False
        
        # URL de base pour l'API Vertex AI
        if self.project_id and self.api_key and self.enabled:
            self.base_url = f"https://{self.region}-aiplatform.googleapis.com/v1/projects/{self.project_id}/locations/{self.region}/publishers/google/models/{self.model_name}"
            self._initialize_api()
        else:
            self.logger.warning("Configuration Vertex AI incompl√®te - fonctionnement en mode simulation")
    
    def _initialize_api(self):
        """Initialise la connexion √† l'API Gemini"""
        try:
            # Test de connectivit√© avec l'API Gemini
            test_prompt = "Test de connectivit√©. R√©pondez simplement 'OK'."
            
            response = self._make_api_request(test_prompt, max_tokens=10)
            
            if response and 'candidates' in response and response != self._simulate_response(test_prompt):
                self.is_available = True
                self.logger.info("API Gemini connect√©e avec succ√®s")
            else:
                self.is_available = False
                self.logger.warning("Mode simulation activ√© - impl√©mentation OAuth2 requise pour API r√©elle")
                
        except Exception as e:
            self.logger.error(f"Erreur initialisation API Gemini: {e}")
            self.is_available = False
    
    def _make_api_request(self, prompt: str, max_tokens: int = 1000) -> Optional[Dict]:
        """Effectue une requ√™te √† l'API Gemini"""
        if not self.api_key or self.api_key == "YOUR_VERTEX_AI_API_KEY":
            return self._simulate_response(prompt)
        
        # Essayer l'API Gemini directe (plus simple que Vertex AI)
        try:
            gemini_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key={self.api_key}"
            
            headers = {
                'Content-Type': 'application/json'
            }
            
            payload = {
                "contents": [{
                    "parts": [{"text": prompt}]
                }],
                "generationConfig": {
                    "temperature": 0.1,
                    "maxOutputTokens": max_tokens
                }
            }
            
            response = requests.post(gemini_url, headers=headers, json=payload, timeout=15)
            
            if response.status_code == 200:
                return response.json()
            elif response.status_code == 403:
                self.logger.warning("API Gemini: Cl√© invalide ou API non activ√©e - mode simulation")
                return self._simulate_response(prompt)
            else:
                self.logger.warning(f"API Gemini erreur {response.status_code} - mode simulation")
                return self._simulate_response(prompt)
                
        except Exception as e:
            self.logger.warning(f"Erreur API Gemini: {e} - mode simulation")
            return self._simulate_response(prompt)
    
    def _simulate_response(self, prompt: str) -> Dict:
        """G√©n√®re une r√©ponse simul√©e intelligente"""
        self.logger.info("Mode simulation Vertex AI")
        
        # Analyse du prompt pour g√©n√©rer une r√©ponse coh√©rente
        prompt_lower = prompt.lower()
        
        if "chute" in prompt_lower or "fall" in prompt_lower:
            simulated_analysis = {
                "emergency_type": "Chute d√©tect√©e",
                "urgency_level": 8,
                "urgency_category": "√âlev√©e",
                "immediate_actions": [
                    "V√©rifier si la personne est consciente",
                    "Ne pas d√©placer en cas de blessure",
                    "Appeler les secours si n√©cessaire"
                ],
                "specific_advice": "Une chute peut causer des blessures internes. Surveillance m√©dicale recommand√©e.",
                "emergency_services": "SAMU (15)",
                "reassurance_message": "Les secours sont pr√©venus et peuvent intervenir rapidement.",
                "follow_up_needed": True,
                "medical_priority": "√âlev√©e",
                "recommended_position": "Ne pas d√©placer"
            }
        elif "danger" in prompt_lower or "agression" in prompt_lower:
            simulated_analysis = {
                "emergency_type": "Situation dangereuse",
                "urgency_level": 9,
                "urgency_category": "Critique",
                "immediate_actions": [
                    "Se mettre en s√©curit√©",
                    "Appeler la police",
                    "Alerter les proches"
                ],
                "specific_advice": "Situation potentiellement dangereuse n√©cessitant intervention imm√©diate.",
                "emergency_services": "Police (17)",
                "reassurance_message": "Les forces de s√©curit√© sont alert√©es.",
                "follow_up_needed": True
            }
        elif "malaise" in prompt_lower or "douleur" in prompt_lower:
            simulated_analysis = {
                "emergency_type": "Urgence m√©dicale",
                "urgency_level": 7,
                "urgency_category": "√âlev√©e",
                "immediate_actions": [
                    "S'asseoir ou s'allonger",
                    "Respirer calmement",
                    "Contacter le SAMU"
                ],
                "specific_advice": "Malaise n√©cessitant une √©valuation m√©dicale rapide.",
                "emergency_services": "SAMU (15)",
                "reassurance_message": "Une √©quipe m√©dicale peut intervenir rapidement.",
                "follow_up_needed": True
            }
        else:
            simulated_analysis = {
                "emergency_type": "Urgence g√©n√©rale",
                "urgency_level": 6,
                "urgency_category": "Mod√©r√©e",
                "immediate_actions": [
                    "√âvaluer la situation",
                    "Rester calme",
                    "Contacter les personnes appropri√©es"
                ],
                "specific_advice": "Situation n√©cessitant une attention particuli√®re mais pas de panique.",
                "emergency_services": "Num√©ro d'urgence europ√©en (112)",
                "reassurance_message": "La situation est sous contr√¥le et l'aide arrive.",
                "follow_up_needed": True
            }
        
        # Ajouter des champs par d√©faut
        simulated_analysis.setdefault("risk_factors", ["√âvaluation en cours"])
        simulated_analysis.setdefault("what3words", "")
        
        return {
            'candidates': [{
                'content': {
                    'parts': [{'text': json.dumps(simulated_analysis)}]
                }
            }]
        }
    
    def analyze_emergency_situation(self, context: str, location: Tuple[float, float] = None, 
                                  user_input: str = "", time_of_day: str = "jour") -> Dict[str, Any]:
        """Analyse une situation d'urgence avec Vertex AI Gemini"""
        
        # Construction du prompt contextuel
        location_str = f"GPS {location[0]:.6f}, {location[1]:.6f}" if location else "Non disponible"
        
        prompt_parts = [
            "Tu es un expert en gestion d'urgences. Analyse cette situation:",
            f"Contexte: {context}",
            f"Moment: {time_of_day}",
            f"Localisation: {location_str}",
            f"Description utilisateur: {user_input if user_input else 'Aucune'}"
        ]
        
        prompt = " | ".join(prompt_parts)
        
        try:
            response = self._make_api_request(prompt, max_tokens=800)
            
            if response and 'candidates' in response:
                response_text = response['candidates'][0]['content']['parts'][0]['text']
                
                try:
                    analysis = json.loads(response_text.strip())
                    analysis = self._validate_analysis_response(analysis)
                    
                    self.logger.info("Analyse Vertex AI g√©n√©r√©e avec succ√®s")
                    return analysis
                    
                except json.JSONDecodeError as e:
                    self.logger.error(f"Erreur parsing JSON: {e}")
                    return self._fallback_analysis(context)
            
        except Exception as e:
            self.logger.error(f"Erreur analyse Vertex AI: {e}")
        
        return self._fallback_analysis(context)
    
    def _validate_analysis_response(self, analysis: Dict) -> Dict:
        """Valide et nettoie la r√©ponse de l'analyse"""
        
        defaults = {
            "emergency_type": "Urgence",
            "urgency_level": 5,
            "urgency_category": "Mod√©r√©e", 
            "immediate_actions": ["√âvaluer la situation", "Rester calme"],
            "specific_advice": "Situation n√©cessitant attention",
            "emergency_services": "112",
            "reassurance_message": "L'aide est en route",
            "follow_up_needed": True,
            "risk_factors": ["√âvaluation n√©cessaire"],
            "what3words": ""
        }
        
        # Appliquer les valeurs par d√©faut
        for key, default_value in defaults.items():
            if key not in analysis:
                analysis[key] = default_value
        
        # Validation du niveau d'urgence
        try:
            urgency = int(analysis.get('urgency_level', 5))
            analysis['urgency_level'] = max(1, min(10, urgency))
        except (ValueError, TypeError):
            analysis['urgency_level'] = 5
        
        # Validation des actions (max 3)
        actions = analysis.get('immediate_actions', [])
        if isinstance(actions, list) and len(actions) > 3:
            analysis['immediate_actions'] = actions[:3]
        
        return analysis
    
    def _fallback_analysis(self, context: str) -> Dict[str, Any]:
        """Analyse de fallback si Vertex AI √©choue"""
        self.logger.warning("Utilisation analyse de fallback")
        
        context_lower = context.lower()
        
        if any(word in context_lower for word in ['chute', 'tomb√©', 'fall']):
            urgency = 8
            emergency_type = "Chute d√©tect√©e"
            services = "SAMU (15)"
        elif any(word in context_lower for word in ['agression', 'attaque', 'danger']):
            urgency = 9
            emergency_type = "Situation dangereuse"
            services = "Police (17)"
        elif any(word in context_lower for word in ['malaise', 'douleur', 'm√©dical']):
            urgency = 7
            emergency_type = "Urgence m√©dicale"
            services = "SAMU (15)"
        else:
            urgency = 6
            emergency_type = "Urgence g√©n√©rale"
            services = "Num√©ro d'urgence (112)"
        
        return {
            "emergency_type": emergency_type,
            "urgency_level": urgency,
            "urgency_category": "√âlev√©e" if urgency >= 8 else "Mod√©r√©e",
            "immediate_actions": [
                "√âvaluer la situation",
                "Assurer la s√©curit√©", 
                "Demander de l'aide si n√©cessaire"
            ],
            "specific_advice": f"Situation identifi√©e comme: {emergency_type}. Surveillance recommand√©e.",
            "emergency_services": services,
            "reassurance_message": "Nous sommes l√† pour vous aider.",
            "follow_up_needed": True,
            "risk_factors": ["√âvaluation en cours"],
            "what3words": ""
        }
    
    def analyze_fall_emergency(self, fall_info: Dict, user_response: str = None, 
                              context: str = "") -> Dict[str, Any]:
        """Analyse sp√©cialis√©e pour les chutes"""
        
        impact_force = fall_info.get('impact_force', 'mod√©r√©')
        duration = fall_info.get('duration_seconds', 0)
        movement_after = fall_info.get('movement_detected_after', False)
        
        prompt_parts = [
            "Analyse de chute d'urgence:",
            f"Force d'impact: {impact_force}",
            f"Dur√©e: {duration} secondes",
            f"Mouvement apr√®s: {movement_after}",
            f"R√©ponse utilisateur: {user_response or 'Aucune'}",
            f"Contexte: {context}"
        ]
        
        prompt = " | ".join(prompt_parts)
        
        try:
            response = self._make_api_request(prompt, max_tokens=600)
            
            if response and 'candidates' in response:
                response_text = response['candidates'][0]['content']['parts'][0]['text']
                
                try:
                    analysis = json.loads(response_text.strip())
                    analysis = self._validate_fall_analysis(analysis)
                    return analysis
                    
                except json.JSONDecodeError:
                    return self._fallback_fall_analysis(fall_info, user_response)
        
        except Exception as e:
            self.logger.error(f"Erreur analyse chute: {e}")
        
        return self._fallback_fall_analysis(fall_info, user_response)
    
    def _validate_fall_analysis(self, analysis: Dict) -> Dict:
        """Valide l'analyse de chute"""
        
        defaults = {
            "emergency_type": "Chute d√©tect√©e",
            "urgency_level": 7,
            "urgency_category": "√âlev√©e",
            "immediate_actions": ["Ne pas bouger", "V√©rifier conscience", "Appeler secours"],
            "specific_advice": "Chute d√©tect√©e - √©valuation m√©dicale recommand√©e",
            "emergency_services": "SAMU (15)",
            "reassurance_message": "Les secours m√©dicaux peuvent intervenir rapidement",
            "medical_priority": "√âlev√©e",
            "recommended_position": "Ne pas d√©placer",
            "follow_up_needed": True
        }
        
        for key, default_value in defaults.items():
            if key not in analysis:
                analysis[key] = default_value
        
        return analysis
    
    def _fallback_fall_analysis(self, fall_info: Dict, user_response: str) -> Dict:
        """Analyse de fallback pour les chutes"""
        
        impact = fall_info.get('impact_force', 'mod√©r√©')
        movement = fall_info.get('movement_detected_after', False)
        
        if impact == 'fort' or not movement:
            urgency = 9
            priority = "Critique"
        elif user_response and 'va bien' in user_response.lower():
            urgency = 6
            priority = "Moyenne"
        else:
            urgency = 8
            priority = "√âlev√©e"
        
        return {
            "emergency_type": "Chute d√©tect√©e",
            "urgency_level": urgency,
            "urgency_category": "Critique" if urgency >= 9 else "√âlev√©e",
            "immediate_actions": [
                "Ne pas d√©placer la personne",
                "V√©rifier la conscience",
                "Appeler les secours m√©dicaux"
            ],
            "specific_advice": f"Chute avec impact {impact}. √âvaluation m√©dicale n√©cessaire.",
            "emergency_services": "SAMU (15)",
            "reassurance_message": "Une chute a √©t√© d√©tect√©e. Les secours sont alert√©s.",
            "medical_priority": priority,
            "recommended_position": "Position de s√©curit√©, ne pas bouger",
            "follow_up_needed": True
        }
    
    def get_personalized_emergency_message(self, analysis: Dict) -> str:
        """G√©n√®re un message d'urgence personnalis√©"""
        
        emergency_type = analysis.get('emergency_type', 'Urgence')
        urgency_level = analysis.get('urgency_level', 5)
        advice = analysis.get('specific_advice', '')
        
        if urgency_level >= 8:
            intensity = "üö® URGENCE CRITIQUE"
        elif urgency_level >= 6:
            intensity = "‚ö†Ô∏è URGENCE √âLEV√âE"
        else:
            intensity = "üìã SITUATION √Ä SURVEILLER"
        
        message = f"{intensity}\n"
        message += f"Type: {emergency_type}\n"
        message += f"Niveau: {urgency_level}/10\n\n"
        message += f"üí° Conseil: {advice}"
        
        return message
    
    def test_connection(self) -> bool:
        """Test la connexion √† l'API Vertex AI"""
        try:
            response = self._make_api_request("Test", max_tokens=5)
            return response is not None and 'candidates' in response
        except:
            return False
    
    def test_vertex_ai_connection(self) -> Dict[str, Any]:
        """Test la connexion Vertex AI avec retour d√©taill√© (compatibilit√©)"""
        try:
            # Test de base
            connection_ok = self.test_connection()
            
            if connection_ok and self.is_available:
                return {
                    "success": True,
                    "available": True,
                    "details": f"Mod√®le: {self.model_name}, R√©gion: {self.region}",
                    "message": "Vertex AI REST API connect√©e avec succ√®s"
                }
            else:
                return {
                    "success": False,
                    "available": False,
                    "details": f"Mode simulation - Mod√®le: {self.model_name}",
                    "message": "Vertex AI en mode simulation (cl√© API manquante ou OAuth2 non impl√©ment√©)"
                }
        
        except Exception as e:
            return {
                "success": False,
                "available": False,
                "details": "Erreur de connexion",
                "message": f"Erreur de connexion: {e}"
            }