"""
Vertex AI Agent for GuardianNav - API REST Version
Advanced emergency analysis using Google Cloud Vertex AI via REST API
"""
import logging
import json
import requests
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime

class VertexAIAgent:
    """Agent Vertex AI pour l'analyse d'urgence avancÃ©e avec Gemini via API REST"""
    
    def __init__(self, api_keys_config: Dict[str, Any] = None):
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        
        # Configuration API
        self.api_keys_config = api_keys_config or {}
        vertex_config = self.api_keys_config.get('google_cloud', {}).get('vertex_ai', {})
        
        self.project_id = self.api_keys_config.get('google_cloud', {}).get('project_id')
        self.region = vertex_config.get('region', 'europe-west1')
        self.api_key = vertex_config.get('api_key')
        self.enabled = vertex_config.get('enabled', True)
        
        # Configuration du modÃ¨le
        self.model_name = "gemini-1.5-flash-002"
        self.is_available = False
        
        # URL de base pour l'API Vertex AI
        if self.project_id and self.api_key and self.enabled:
            self.base_url = f"https://{self.region}-aiplatform.googleapis.com/v1/projects/{self.project_id}/locations/{self.region}/publishers/google/models/{self.model_name}"
            self._initialize_api()
        else:
            self.logger.warning("Configuration Vertex AI incomplÃ¨te - fonctionnement en mode simulation")
    
    def _initialize_api(self):
        """Initialise la connexion Ã  l'API Vertex AI"""
        try:
            # Note: Pour l'authentification, nous devrons utiliser OAuth2 ou service account
            # Pour simplifier le test, nous commenÃ§ons en mode simulation
            self.logger.warning("âš ï¸ Mode simulation activÃ© - implÃ©mentation OAuth2 requise pour API rÃ©elle")
            self.is_available = False  # Sera True quand OAuth2 sera implÃ©mentÃ©
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur initialisation Vertex AI API: {e}")
            self.is_available = False
    
    def _make_api_request(self, prompt: str, max_tokens: int = 1000) -> Optional[Dict]:
        """Effectue une requÃªte Ã  l'API Vertex AI (actuellement en simulation)"""
        # Mode simulation pour le dÃ©veloppement
        return self._simulate_response(prompt)
    
    def _simulate_response(self, prompt: str) -> Dict:
        """GÃ©nÃ¨re une rÃ©ponse simulÃ©e intelligente"""
        self.logger.info("ðŸŽ­ Mode simulation Vertex AI")
        
        # Analyse du prompt pour gÃ©nÃ©rer une rÃ©ponse cohÃ©rente
        prompt_lower = prompt.lower()
        
        if "chute" in prompt_lower or "fall" in prompt_lower:
            simulated_analysis = {
                "emergency_type": "Chute dÃ©tectÃ©e",
                "urgency_level": 8,
                "urgency_category": "Ã‰levÃ©e",
                "immediate_actions": [
                    "VÃ©rifier si la personne est consciente",
                    "Ne pas dÃ©placer en cas de blessure",
                    "Appeler les secours si nÃ©cessaire"
                ],
                "specific_advice": "Une chute peut causer des blessures internes. Surveillance mÃ©dicale recommandÃ©e.",
                "emergency_services": "SAMU (15)",
                "reassurance_message": "Les secours sont prÃ©venus et peuvent intervenir rapidement.",
                "follow_up_needed": True,
                "medical_priority": "Ã‰levÃ©e",
                "recommended_position": "Ne pas dÃ©placer"
            }
        elif "danger" in prompt_lower or "agression" in prompt_lower:
            simulated_analysis = {
                "emergency_type": "Situation dangereuse",
                "urgency_level": 9,
                "urgency_category": "Critique",
                "immediate_actions": [
                    "Se mettre en sÃ©curitÃ©",
                    "Appeler la police",
                    "Alerter les proches"
                ],
                "specific_advice": "Situation potentiellement dangereuse nÃ©cessitant intervention immÃ©diate.",
                "emergency_services": "Police (17)",
                "reassurance_message": "Les forces de sÃ©curitÃ© sont alertÃ©es.",
                "follow_up_needed": True
            }
        elif "malaise" in prompt_lower or "douleur" in prompt_lower:
            simulated_analysis = {
                "emergency_type": "Urgence mÃ©dicale",
                "urgency_level": 7,
                "urgency_category": "Ã‰levÃ©e",
                "immediate_actions": [
                    "S'asseoir ou s'allonger",
                    "Respirer calmement",
                    "Contacter le SAMU"
                ],
                "specific_advice": "Malaise nÃ©cessitant une Ã©valuation mÃ©dicale rapide.",
                "emergency_services": "SAMU (15)",
                "reassurance_message": "Une Ã©quipe mÃ©dicale peut intervenir rapidement.",
                "follow_up_needed": True
            }
        else:
            simulated_analysis = {
                "emergency_type": "Urgence gÃ©nÃ©rale",
                "urgency_level": 6,
                "urgency_category": "ModÃ©rÃ©e",
                "immediate_actions": [
                    "Ã‰valuer la situation",
                    "Rester calme",
                    "Contacter les personnes appropriÃ©es"
                ],
                "specific_advice": "Situation nÃ©cessitant une attention particuliÃ¨re mais pas de panique.",
                "emergency_services": "NumÃ©ro d'urgence europÃ©en (112)",
                "reassurance_message": "La situation est sous contrÃ´le et l'aide arrive.",
                "follow_up_needed": True
            }
        
        # Ajouter des champs par dÃ©faut
        simulated_analysis.setdefault("risk_factors", ["Ã‰valuation en cours"])
        simulated_analysis.setdefault("what3words", "")
        
        return {
            'candidates': [{
                'content': {
                    'parts': [{'text': json.dumps(simulated_analysis)}]
                }
            }]
        }
    
    def analyze_emergency_situation(self, context: str, location: Tuple[float, float] = None, 
                                  user_input: str = "", time_of_day: str = "jour") -> Dict[str, Any]:
        """Analyse une situation d'urgence avec Vertex AI Gemini"""
        
        # Construction du prompt contextuel
        location_str = f"GPS {location[0]:.6f}, {location[1]:.6f}" if location else "Non disponible"
        
        prompt_parts = [
            "Tu es un expert en gestion d'urgences. Analyse cette situation:",
            f"Contexte: {context}",
            f"Moment: {time_of_day}",
            f"Localisation: {location_str}",
            f"Description utilisateur: {user_input if user_input else 'Aucune'}"
        ]
        
        prompt = " | ".join(prompt_parts)
        
        try:
            response = self._make_api_request(prompt, max_tokens=800)
            
            if response and 'candidates' in response:
                response_text = response['candidates'][0]['content']['parts'][0]['text']
                
                try:
                    analysis = json.loads(response_text.strip())
                    analysis = self._validate_analysis_response(analysis)
                    
                    self.logger.info("âœ… Analyse Vertex AI gÃ©nÃ©rÃ©e avec succÃ¨s")
                    return analysis
                    
                except json.JSONDecodeError as e:
                    self.logger.error(f"Erreur parsing JSON: {e}")
                    return self._fallback_analysis(context)
            
        except Exception as e:
            self.logger.error(f"Erreur analyse Vertex AI: {e}")
        
        return self._fallback_analysis(context)
    
    def _validate_analysis_response(self, analysis: Dict) -> Dict:
        """Valide et nettoie la rÃ©ponse de l'analyse"""
        
        defaults = {
            "emergency_type": "Urgence",
            "urgency_level": 5,
            "urgency_category": "ModÃ©rÃ©e", 
            "immediate_actions": ["Ã‰valuer la situation", "Rester calme"],
            "specific_advice": "Situation nÃ©cessitant attention",
            "emergency_services": "112",
            "reassurance_message": "L'aide est en route",
            "follow_up_needed": True,
            "risk_factors": ["Ã‰valuation nÃ©cessaire"],
            "what3words": ""
        }
        
        # Appliquer les valeurs par dÃ©faut
        for key, default_value in defaults.items():
            if key not in analysis:
                analysis[key] = default_value
        
        # Validation du niveau d'urgence
        try:
            urgency = int(analysis.get('urgency_level', 5))
            analysis['urgency_level'] = max(1, min(10, urgency))
        except (ValueError, TypeError):
            analysis['urgency_level'] = 5
        
        # Validation des actions (max 3)
        actions = analysis.get('immediate_actions', [])
        if isinstance(actions, list) and len(actions) > 3:
            analysis['immediate_actions'] = actions[:3]
        
        return analysis
    
    def _fallback_analysis(self, context: str) -> Dict[str, Any]:
        """Analyse de fallback si Vertex AI Ã©choue"""
        self.logger.warning("ðŸ”„ Utilisation analyse de fallback")
        
        context_lower = context.lower()
        
        if any(word in context_lower for word in ['chute', 'tombÃ©', 'fall']):
            urgency = 8
            emergency_type = "Chute dÃ©tectÃ©e"
            services = "SAMU (15)"
        elif any(word in context_lower for word in ['agression', 'attaque', 'danger']):
            urgency = 9
            emergency_type = "Situation dangereuse"
            services = "Police (17)"
        elif any(word in context_lower for word in ['malaise', 'douleur', 'mÃ©dical']):
            urgency = 7
            emergency_type = "Urgence mÃ©dicale"
            services = "SAMU (15)"
        else:
            urgency = 6
            emergency_type = "Urgence gÃ©nÃ©rale"
            services = "NumÃ©ro d'urgence (112)"
        
        return {
            "emergency_type": emergency_type,
            "urgency_level": urgency,
            "urgency_category": "Ã‰levÃ©e" if urgency >= 8 else "ModÃ©rÃ©e",
            "immediate_actions": [
                "Ã‰valuer la situation",
                "Assurer la sÃ©curitÃ©", 
                "Demander de l'aide si nÃ©cessaire"
            ],
            "specific_advice": f"Situation identifiÃ©e comme: {emergency_type}. Surveillance recommandÃ©e.",
            "emergency_services": services,
            "reassurance_message": "Nous sommes lÃ  pour vous aider.",
            "follow_up_needed": True,
            "risk_factors": ["Ã‰valuation en cours"],
            "what3words": ""
        }
    
    def analyze_fall_emergency(self, fall_info: Dict, user_response: str = None, 
                              context: str = "") -> Dict[str, Any]:
        """Analyse spÃ©cialisÃ©e pour les chutes"""
        
        impact_force = fall_info.get('impact_force', 'modÃ©rÃ©')
        duration = fall_info.get('duration_seconds', 0)
        movement_after = fall_info.get('movement_detected_after', False)
        
        prompt_parts = [
            "Analyse de chute d'urgence:",
            f"Force d'impact: {impact_force}",
            f"DurÃ©e: {duration} secondes",
            f"Mouvement aprÃ¨s: {movement_after}",
            f"RÃ©ponse utilisateur: {user_response or 'Aucune'}",
            f"Contexte: {context}"
        ]
        
        prompt = " | ".join(prompt_parts)
        
        try:
            response = self._make_api_request(prompt, max_tokens=600)
            
            if response and 'candidates' in response:
                response_text = response['candidates'][0]['content']['parts'][0]['text']
                
                try:
                    analysis = json.loads(response_text.strip())
                    analysis = self._validate_fall_analysis(analysis)
                    return analysis
                    
                except json.JSONDecodeError:
                    return self._fallback_fall_analysis(fall_info, user_response)
        
        except Exception as e:
            self.logger.error(f"Erreur analyse chute: {e}")
        
        return self._fallback_fall_analysis(fall_info, user_response)
    
    def _validate_fall_analysis(self, analysis: Dict) -> Dict:
        """Valide l'analyse de chute"""
        
        defaults = {
            "emergency_type": "Chute dÃ©tectÃ©e",
            "urgency_level": 7,
            "urgency_category": "Ã‰levÃ©e",
            "immediate_actions": ["Ne pas bouger", "VÃ©rifier conscience", "Appeler secours"],
            "specific_advice": "Chute dÃ©tectÃ©e - Ã©valuation mÃ©dicale recommandÃ©e",
            "emergency_services": "SAMU (15)",
            "reassurance_message": "Les secours mÃ©dicaux peuvent intervenir rapidement",
            "medical_priority": "Ã‰levÃ©e",
            "recommended_position": "Ne pas dÃ©placer",
            "follow_up_needed": True
        }
        
        for key, default_value in defaults.items():
            if key not in analysis:
                analysis[key] = default_value
        
        return analysis
    
    def _fallback_fall_analysis(self, fall_info: Dict, user_response: str) -> Dict:
        """Analyse de fallback pour les chutes"""
        
        impact = fall_info.get('impact_force', 'modÃ©rÃ©')
        movement = fall_info.get('movement_detected_after', False)
        
        if impact == 'fort' or not movement:
            urgency = 9
            priority = "Critique"
        elif user_response and 'va bien' in user_response.lower():
            urgency = 6
            priority = "Moyenne"
        else:
            urgency = 8
            priority = "Ã‰levÃ©e"
        
        return {
            "emergency_type": "Chute dÃ©tectÃ©e",
            "urgency_level": urgency,
            "urgency_category": "Critique" if urgency >= 9 else "Ã‰levÃ©e",
            "immediate_actions": [
                "Ne pas dÃ©placer la personne",
                "VÃ©rifier la conscience",
                "Appeler les secours mÃ©dicaux"
            ],
            "specific_advice": f"Chute avec impact {impact}. Ã‰valuation mÃ©dicale nÃ©cessaire.",
            "emergency_services": "SAMU (15)",
            "reassurance_message": "Une chute a Ã©tÃ© dÃ©tectÃ©e. Les secours sont alertÃ©s.",
            "medical_priority": priority,
            "recommended_position": "Position de sÃ©curitÃ©, ne pas bouger",
            "follow_up_needed": True
        }
    
    def get_personalized_emergency_message(self, analysis: Dict) -> str:
        """GÃ©nÃ¨re un message d'urgence personnalisÃ©"""
        
        emergency_type = analysis.get('emergency_type', 'Urgence')
        urgency_level = analysis.get('urgency_level', 5)
        advice = analysis.get('specific_advice', '')
        
        if urgency_level >= 8:
            intensity = "ðŸš¨ URGENCE CRITIQUE"
        elif urgency_level >= 6:
            intensity = "âš ï¸ URGENCE Ã‰LEVÃ‰E"
        else:
            intensity = "ðŸ“‹ SITUATION Ã€ SURVEILLER"
        
        message = f"{intensity}\n"
        message += f"Type: {emergency_type}\n"
        message += f"Niveau: {urgency_level}/10\n\n"
        message += f"ðŸ’¡ Conseil: {advice}"
        
        return message
    
    def test_connection(self) -> bool:
        """Test la connexion Ã  l'API Vertex AI"""
        try:
            response = self._make_api_request("Test", max_tokens=5)
            return response is not None and 'candidates' in response
        except:
            return False