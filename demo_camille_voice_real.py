#!/usr/bin/env python3
"""
D√âMO GUARDIANNAV - SC√âNARIO CAMILLE AVEC VRAIE RECONNAISSANCE VOCALE
D√©monstration avec speech-to-text r√©el (Vosk) + IA Gemini
Personnage : Camille, pr√®s des locaux Google, 22h, vendredi 31 octobre
"""

import sys
import os
import yaml
import json
import threading
import time
from datetime import datetime

# Ajouter le chemin vers les modules GuardianNav
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Imports pour la reconnaissance vocale
try:
    import vosk
    import sounddevice as sd
    import queue
    VOICE_AVAILABLE = True
except ImportError as e:
    print(f"‚ùå Erreur import vocal: {e}")
    VOICE_AVAILABLE = False

# Imports pour la synth√®se vocale 
try:
    import pygame
    TTS_AVAILABLE = True
except ImportError:
    TTS_AVAILABLE = False

class VoiceRecognizer:
    """Gestionnaire de reconnaissance vocale avec Vosk"""
    
    def __init__(self, model_path="vosk-model-small-fr-0.22"):
        self.model_path = model_path
        self.model = None
        self.rec = None
        self.audio_queue = queue.Queue()
        self.is_listening = False
        
    def initialize(self):
        """Initialise le mod√®le Vosk"""
        try:
            if not os.path.exists(self.model_path):
                print(f"‚ùå Mod√®le Vosk non trouv√©: {self.model_path}")
                return False
                
            print("üîß Chargement du mod√®le Vosk fran√ßais...")
            self.model = vosk.Model(self.model_path)
            self.rec = vosk.KaldiRecognizer(self.model, 16000)
            print("‚úÖ Mod√®le Vosk charg√© avec succ√®s")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur initialisation Vosk: {e}")
            return False
    
    def audio_callback(self, indata, frames, time, status):
        """Callback pour capturer l'audio"""
        if status:
            print(f"‚ö†Ô∏è Audio status: {status}")
        self.audio_queue.put(bytes(indata))
    
    def listen_for_speech(self, timeout=30, stop_words=['stop', 'arr√™t', 'arr√™te']):
        """√âcoute et reconna√Æt la parole"""
        if not self.model:
            return None
            
        try:
            print(f"üé§ **√âCOUTE ACTIV√âE** (timeout: {timeout}s)")
            print("üó£Ô∏è Parlez maintenant... (dites 'stop' pour terminer)")
            print("-" * 50)
            
            self.is_listening = True
            recognized_text = ""
            
            with sd.RawInputStream(samplerate=16000, blocksize=8000, device=None, 
                                   dtype='int16', channels=1, callback=self.audio_callback):
                
                start_time = time.time()
                
                while self.is_listening and (time.time() - start_time) < timeout:
                    try:
                        data = self.audio_queue.get(timeout=1)
                        
                        if self.rec.AcceptWaveform(data):
                            # Phrase compl√®te reconnue
                            result = json.loads(self.rec.Result())
                            text = result.get('text', '').strip()
                            
                            if text:
                                print(f"üó£Ô∏è **RECONNU:** '{text}'")
                                recognized_text = text
                                
                                # V√©rifier les mots d'arr√™t
                                if any(stop_word in text.lower() for stop_word in stop_words):
                                    print("üõë Mot d'arr√™t d√©tect√©")
                                    break
                                else:
                                    # Phrase reconnue, on peut s'arr√™ter
                                    break
                        else:
                            # Reconnaissance partielle
                            partial = json.loads(self.rec.PartialResult())
                            partial_text = partial.get('partial', '').strip()
                            if partial_text:
                                print(f"üéß [En cours...]: {partial_text}", end='\r')
                                
                    except queue.Empty:
                        continue
                    except Exception as e:
                        print(f"‚ùå Erreur reconnaissance: {e}")
                        break
            
            self.is_listening = False
            print(f"\n‚úÖ Reconnaissance termin√©e: '{recognized_text}'")
            return recognized_text if recognized_text else None
            
        except Exception as e:
            print(f"‚ùå Erreur √©coute: {e}")
            self.is_listening = False
            return None

def load_guardian_agent():
    """Charge l'agent GuardianNav avec configuration"""
    try:
        # Charger la configuration
        with open('api_keys.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # Importer et initialiser l'agent
        from guardian.gemini_agent import VertexAIAgent
        agent = VertexAIAgent(config)
        
        return agent, True
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur chargement agent: {e}")
        return None, False

def simulate_tts_response(text):
    """Simule la synth√®se vocale"""
    print("\nüîä **GUARDIANNAV R√âPOND:**")
    print("="*60)
    print(f"{text}")
    print("="*60)
    print()

def analyze_situation_with_ai(agent, situation_text):
    """Analyse la situation avec l'IA"""
    if not agent:
        return simulate_ai_response(situation_text)
    
    try:
        print("üß† [Analyse IA Gemini en cours...]")
        response = agent._make_api_request(situation_text)
        
        if response and 'candidates' in response:
            ai_text = response['candidates'][0]['content']['parts'][0]['text']
            return ai_text
        else:
            return simulate_ai_response(situation_text)
            
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur IA: {e}")
        return simulate_ai_response(situation_text)

def simulate_ai_response(situation_text):
    """G√©n√®re une r√©ponse IA simul√©e pour le sc√©nario"""
    return """**ANALYSE D'URGENCE - NIVEAU 8/10**

**Situation identifi√©e :** S√©curit√© personnelle compromise
**Lieu :** Zone urbaine, proximit√© bureaux, heure tardive
**Facteurs de risque :** Isolement, impression d'√™tre suivie, environnement peu familier

**ACTIONS IMM√âDIATES RECOMMAND√âES :**

1. **S√âCURIT√â IMM√âDIATE**
   ‚Ä¢ Dirigez-vous vers un lieu s√ªr et √©clair√© (magasin ouvert, restaurant, hall d'immeuble s√©curis√©)
   ‚Ä¢ √âvitez les ruelles sombres et les zones isol√©es
   
2. **CONTACT D'URGENCE** 
   ‚Ä¢ Appelez le 17 (Police) si menace imm√©diate
   ‚Ä¢ Contactez un proche de confiance pour signaler votre position
   
3. **TRANSPORT S√âCURIS√â**
   ‚Ä¢ Commandez un taxi/VTC avec partage de trajet en temps r√©el
   ‚Ä¢ √âvitez les transports en commun seule √† cette heure

**Camille, votre s√©curit√© est la priorit√© absolue. Faites confiance √† votre instinct.**"""

def display_scenario_intro():
    """Affiche l'introduction du sc√©nario"""
    print("üé≠ D√âMO GUARDIANNAV - SC√âNARIO CAMILLE (RECONNAISSANCE VOCALE)")
    print("="*70)
    print("üë§ **PERSONNAGE :** Camille")
    print("üìç **LOCALISATION :** Pr√®s des locaux Google")  
    print("üïô **HEURE :** 22h00")
    print("üìÖ **DATE :** Vendredi 31 octobre 2025")
    print("‚ö†Ô∏è **SITUATION :** Je me sens en danger")
    print("="*70)
    print()
    
    print("üéØ **CONTEXTE DU SC√âNARIO:**")
    print("Vous √™tes Camille, il est tard le soir, vous √™tes seule pr√®s")
    print("des bureaux Google dans un quartier que vous ne connaissez pas bien.")
    print("Vous avez l'impression d'√™tre suivie et vous commencez √† avoir peur.")
    print("Vous d√©cidez d'activer GuardianNav pour obtenir de l'aide.")
    print()
    
    print("üéôÔ∏è **VRAIE RECONNAISSANCE VOCALE:**")
    print("‚Ä¢ Parlez dans votre microphone pour interagir üé§")
    print("‚Ä¢ GuardianNav utilisera Vosk pour vous comprendre üó£Ô∏è")
    print("‚Ä¢ L'IA Gemini analysera votre situation en temps r√©el üß†")
    print("‚Ä¢ Dites 'stop' ou 'arr√™t' pour terminer une √©coute")
    print()

def run_voice_camille_demo():
    """Lance la d√©monstration du sc√©nario Camille avec vraie reconnaissance vocale"""
    
    # Introduction
    display_scenario_intro()
    
    # V√©rification des pr√©requis
    if not VOICE_AVAILABLE:
        print("‚ùå Modules de reconnaissance vocale non disponibles")
        print("üí° Installez avec: pip3 install vosk sounddevice")
        return
    
    input("üöÄ Appuyez sur Entr√©e pour commencer la d√©mo avec reconnaissance vocale...")
    print()
    
    # Initialisation de la reconnaissance vocale
    print("üé§ **INITIALISATION RECONNAISSANCE VOCALE**")
    print("="*50)
    recognizer = VoiceRecognizer()
    
    if not recognizer.initialize():
        print("‚ùå Impossible d'initialiser la reconnaissance vocale")
        print("üí° V√©rifiez que le mod√®le vosk-model-small-fr-0.22 est pr√©sent")
        return
    
    # Chargement de l'agent
    print("\nüîß **INITIALISATION DE GUARDIANNAV**")
    print("="*40)
    agent, agent_loaded = load_guardian_agent()
    
    if agent_loaded:
        print("‚úÖ Agent GuardianNav charg√© avec succ√®s")
        print(f"ü§ñ IA Gemini: {'‚úÖ Disponible' if agent.is_available else '‚ö†Ô∏è Mode simulation'}")
    else:
        print("‚ö†Ô∏è Agent en mode simulation")
    
    print()
    
    # D√©but de la conversation
    print("üéôÔ∏è **D√âBUT DE LA CONVERSATION VOCALE**")
    print("="*45)
    
    # Message d'accueil GuardianNav
    welcome_msg = """Bonjour Camille. Je suis GuardianNav, votre assistant de s√©curit√© personnel. 
Je d√©tecte que vous m'activez √† une heure tardive. √ätes-vous en s√©curit√© ? 
D√©crivez-moi votre situation actuelle en parlant dans votre microphone."""
    
    simulate_tts_response(welcome_msg)
    
    # Premi√®re interaction - Camille explique sa situation avec sa voix
    print("üé§ **√Ä VOUS DE PARLER, CAMILLE...**")
    situation_vocale = recognizer.listen_for_speech(timeout=20)
    
    if not situation_vocale:
        print("‚ö†Ô∏è Aucune parole d√©tect√©e, utilisation du sc√©nario par d√©faut")
        situation_vocale = "Je suis pr√®s des bureaux Google, il est 22h, je rentre du travail et j'ai l'impression qu'on me suit. Il y a quelqu'un derri√®re moi depuis plusieurs rues et √ßa me fait peur. Je ne sais pas quoi faire."
    
    print(f"\nüìù **SITUATION RAPPORT√âE:** {situation_vocale}")
    
    # Construction du prompt contextualis√©
    full_prompt = f"""
    SITUATION D'URGENCE - ANALYSE REQUISE
    
    Personne: Camille (femme)
    Heure: 22h00, vendredi 31 octobre 2025
    Lieu: Pr√®s des locaux Google (zone urbaine)
    
    Situation rapport√©e par reconnaissance vocale: "{situation_vocale}"
    
    En tant que GuardianNav, assistant IA de s√©curit√© personnelle, analysez cette situation et fournissez:
    1. Niveau d'urgence (1-10)
    2. Type de situation
    3. Conseils imm√©diats et pratiques
    4. Actions concr√®tes √† prendre
    
    R√©pondez de mani√®re rassurante mais ferme, en fran√ßais, comme si vous parliez directement √† Camille.
    Soyez concis mais complet.
    """
    
    # Analyse IA
    print("\nüß† **ANALYSE INTELLIGENTE GUARDIANNAV**")
    print("="*45)
    ai_response = analyze_situation_with_ai(agent, full_prompt)
    
    simulate_tts_response(ai_response)
    
    # Suivi de situation avec reconnaissance vocale
    print("üé§ **SUIVI VOCAL - COMMENT ALLEZ-VOUS MAINTENANT ?**")
    follow_up_vocal = recognizer.listen_for_speech(timeout=15)
    
    # R√©ponse de suivi
    if follow_up_vocal:
        print(f"\nüìù **MISE √Ä JOUR:** {follow_up_vocal}")
        
        follow_prompt = f"""
        SUIVI DE SITUATION - Camille r√©pond par reconnaissance vocale: "{follow_up_vocal}"
        
        Contexte: Camille √©tait pr√®s des locaux Google √† 22h, se sentait suivie.
        Votre analyse pr√©c√©dente lui a donn√© des conseils de s√©curit√©.
        
        R√©pondez √† sa mise √† jour de mani√®re bienveillante et donnez des conseils de suivi appropri√©s.
        Si elle est en s√©curit√©, f√©licitez-la et donnez des conseils pour rentrer chez elle.
        Si elle est encore en danger, renforcez les mesures de s√©curit√©.
        Soyez concis et rassurant.
        """
        
        follow_response = analyze_situation_with_ai(agent, follow_prompt)
        simulate_tts_response(follow_response)
    else:
        print("‚ö†Ô∏è Pas de r√©ponse vocale d√©tect√©e")
    
    # Conclusion
    print("\nüéØ **CONCLUSION DE LA D√âMO VOCALE**")
    print("="*40)
    print("‚úÖ D√©monstration vocale termin√©e avec succ√®s")
    print("üé≠ Sc√©nario Camille avec vraie reconnaissance vocale")
    print("ü§ñ GuardianNav + Vosk + Gemini IA")
    print()
    print("üí° **POINTS CL√âS D√âMONTR√âS:**")
    print("   ‚úÖ Reconnaissance vocale fran√ßaise (Vosk)")
    print("   ‚úÖ Analyse IA contextuelle (Gemini)")
    print("   ‚úÖ Conversation naturelle speech-to-text")
    print("   ‚úÖ Conseils de s√©curit√© personnalis√©s")
    print("   ‚úÖ Suivi en temps r√©el de la situation")
    print()
    print("üöÄ System complet op√©rationnel pour situations r√©elles !")

def main():
    """Point d'entr√©e principal"""
    try:
        run_voice_camille_demo()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è D√©mo interrompue par l'utilisateur")
        print("üõ°Ô∏è En situation r√©elle, GuardianNav resterait disponible")
    except Exception as e:
        print(f"\n‚ùå Erreur durant la d√©mo: {e}")
        print("üí° En cas de vraie urgence, contactez directement le 17 ou le 112")

if __name__ == "__main__":
    main()